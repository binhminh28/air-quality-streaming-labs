#!/usr/bin/env python3
"""
Script debug to√†n b·ªô h·ªá th·ªëng Air Quality Streaming
Ki·ªÉm tra t·∫•t c·∫£ c√°c component: Docker, Kafka, Spark, Cassandra, Dashboard
"""

import subprocess
import sys
import os
import time
from datetime import datetime
from cassandra.cluster import Cluster
from cassandra.auth import PlainTextAuthProvider
import json

# Colors for output
class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    RESET = '\033[0m'
    BOLD = '\033[1m'

def print_header(text):
    print(f"\n{Colors.BOLD}{Colors.BLUE}{'='*60}{Colors.RESET}")
    print(f"{Colors.BOLD}{Colors.BLUE}{text}{Colors.RESET}")
    print(f"{Colors.BOLD}{Colors.BLUE}{'='*60}{Colors.RESET}\n")

def print_success(text):
    print(f"{Colors.GREEN}‚úÖ {text}{Colors.RESET}")

def print_error(text):
    print(f"{Colors.RED}‚ùå {text}{Colors.RESET}")

def print_warning(text):
    print(f"{Colors.YELLOW}‚ö†Ô∏è  {text}{Colors.RESET}")

def print_info(text):
    print(f"{Colors.BLUE}‚ÑπÔ∏è  {text}{Colors.RESET}")

def check_docker_services():
    """Ki·ªÉm tra c√°c Docker services"""
    print_header("1. KI·ªÇM TRA DOCKER SERVICES")
    
    try:
        result = subprocess.run(
            ['docker', 'ps', '--format', '{{.Names}}\t{{.Status}}'],
            capture_output=True,
            text=True,
            check=True
        )
        
        services = {
            'zookeeper': False,
            'kafka': False,
            'cassandra': False
        }
        
        for line in result.stdout.strip().split('\n'):
            if line:
                name, status = line.split('\t')
                if 'zookeeper' in name.lower():
                    services['zookeeper'] = True
                    print_success(f"Zookeeper: {name} - {status}")
                elif 'kafka' in name.lower():
                    services['kafka'] = True
                    print_success(f"Kafka: {name} - {status}")
                elif 'cassandra' in name.lower():
                    services['cassandra'] = True
                    print_success(f"Cassandra: {name} - {status}")
        
        for service, running in services.items():
            if not running:
                print_error(f"{service.capitalize()} kh√¥ng ƒëang ch·∫°y!")
        
        return all(services.values())
    except subprocess.CalledProcessError as e:
        print_error(f"L·ªói khi ki·ªÉm tra Docker: {e}")
        return False
    except FileNotFoundError:
        print_error("Docker kh√¥ng ƒë∆∞·ª£c c√†i ƒë·∫∑t ho·∫∑c kh√¥ng c√≥ trong PATH")
        return False

def check_kafka_topic():
    """Ki·ªÉm tra Kafka topic v√† messages"""
    print_header("2. KI·ªÇM TRA KAFKA TOPIC")
    
    try:
        # Ki·ªÉm tra topic t·ªìn t·∫°i
        result = subprocess.run(
            ['docker', 'exec', 'kafka', 'kafka-topics', '--list', '--bootstrap-server', 'localhost:29092'],
            capture_output=True,
            text=True,
            check=True
        )
        
        topics = result.stdout.strip().split('\n')
        if 'air_quality_realtime' in topics:
            print_success(f"Topic 'air_quality_realtime' t·ªìn t·∫°i")
        else:
            print_error("Topic 'air_quality_realtime' kh√¥ng t·ªìn t·∫°i!")
            return False
        
        # Ki·ªÉm tra s·ªë l∆∞·ª£ng messages trong topic
        result = subprocess.run(
            ['docker', 'exec', 'kafka', 'kafka-run-class', 'kafka.tools.GetOffsetShell',
             '--broker-list', 'localhost:29092',
             '--topic', 'air_quality_realtime'],
            capture_output=True,
            text=True,
            check=True
        )
        
        if result.stdout:
            offsets = result.stdout.strip().split('\n')
            total_messages = 0
            for offset_line in offsets:
                if ':' in offset_line:
                    parts = offset_line.split(':')
                    if len(parts) >= 3:
                        total_messages += int(parts[2])
            print_info(f"T·ªïng s·ªë messages trong topic: {total_messages}")
            
            # L·∫•y message m·ªõi nh·∫•t
            result = subprocess.run(
                ['docker', 'exec', 'kafka', 'kafka-console-consumer',
                 '--bootstrap-server', 'localhost:29092',
                 '--topic', 'air_quality_realtime',
                 '--from-beginning',
                 '--max-messages', '1',
                 '--timeout-ms', '5000'],
                capture_output=True,
                text=True,
                timeout=10
            )
            
            if result.stdout:
                print_success(f"Message m·ªõi nh·∫•t: {result.stdout.strip()[:100]}")
            else:
                print_warning("Kh√¥ng c√≥ message n√†o trong topic")
        else:
            print_warning("Kh√¥ng th·ªÉ l·∫•y th√¥ng tin v·ªÅ messages")
        
        return True
    except subprocess.CalledProcessError as e:
        print_error(f"L·ªói khi ki·ªÉm tra Kafka: {e}")
        print_error(f"Output: {e.stderr}")
        return False
    except subprocess.TimeoutExpired:
        print_warning("Timeout khi l·∫•y message m·ªõi nh·∫•t")
        return True
    except Exception as e:
        print_error(f"L·ªói kh√¥ng mong ƒë·ª£i: {e}")
        return False

def check_kafka_producer():
    """Ki·ªÉm tra Kafka Producer c√≥ ƒëang ch·∫°y kh√¥ng"""
    print_header("3. KI·ªÇM TRA KAFKA PRODUCER")
    
    try:
        result = subprocess.run(
            ['ps', 'aux'],
            capture_output=True,
            text=True,
            check=True
        )
        
        producer_running = False
        for line in result.stdout.split('\n'):
            if 'producer.py' in line and 'python' in line.lower():
                producer_running = True
                parts = line.split()
                pid = parts[1]
                print_success(f"Producer ƒëang ch·∫°y (PID: {pid})")
                print_info(f"Command: {' '.join(parts[10:])}")
                break
        
        if not producer_running:
            print_error("Producer KH√îNG ƒëang ch·∫°y!")
            print_info("Ch·∫°y: python kafka/producer.py")
        
        return producer_running
    except Exception as e:
        print_error(f"L·ªói khi ki·ªÉm tra Producer: {e}")
        return False

def check_spark_streaming():
    """Ki·ªÉm tra Spark Streaming Job"""
    print_header("4. KI·ªÇM TRA SPARK STREAMING JOB")
    
    try:
        result = subprocess.run(
            ['ps', 'aux'],
            capture_output=True,
            text=True,
            check=True
        )
        
        spark_running = False
        for line in result.stdout.split('\n'):
            if 'streaming_job.py' in line and ('spark-submit' in line or 'python' in line.lower()):
                spark_running = True
                parts = line.split()
                pid = parts[1]
                print_success(f"Spark Streaming Job ƒëang ch·∫°y (PID: {pid})")
                print_info(f"Command: {' '.join(parts[10:])}")
                break
        
        if not spark_running:
            print_error("Spark Streaming Job KH√îNG ƒëang ch·∫°y!")
            print_info("Ch·∫°y: bash run_spark_cassandra.sh")
        
        return spark_running
    except Exception as e:
        print_error(f"L·ªói khi ki·ªÉm tra Spark: {e}")
        return False

def check_cassandra_connection():
    """Ki·ªÉm tra k·∫øt n·ªëi Cassandra"""
    print_header("5. KI·ªÇM TRA CASSANDRA CONNECTION")
    
    try:
        cluster = Cluster(['localhost'], port=9042)
        session = cluster.connect()
        print_success("K·∫øt n·ªëi Cassandra th√†nh c√¥ng")
        
        # Ki·ªÉm tra keyspace
        result = session.execute("SELECT keyspace_name FROM system_schema.keyspaces WHERE keyspace_name = 'air_quality'")
        if result.one():
            print_success("Keyspace 'air_quality' t·ªìn t·∫°i")
        else:
            print_error("Keyspace 'air_quality' KH√îNG t·ªìn t·∫°i!")
            cluster.shutdown()
            return False
        
        # Ki·ªÉm tra table
        session.set_keyspace('air_quality')
        result = session.execute("SELECT table_name FROM system_schema.tables WHERE keyspace_name = 'air_quality' AND table_name = 'realtime_data'")
        if result.one():
            print_success("Table 'realtime_data' t·ªìn t·∫°i")
        else:
            print_error("Table 'realtime_data' KH√îNG t·ªìn t·∫°i!")
            cluster.shutdown()
            return False
        
        cluster.shutdown()
        return True
    except Exception as e:
        print_error(f"L·ªói k·∫øt n·ªëi Cassandra: {e}")
        return False

def check_cassandra_data():
    """Ki·ªÉm tra d·ªØ li·ªáu trong Cassandra"""
    print_header("6. KI·ªÇM TRA D·ªÆ LI·ªÜU TRONG CASSANDRA")
    
    try:
        cluster = Cluster(['localhost'], port=9042)
        session = cluster.connect('air_quality')
        
        # ƒê·∫øm t·ªïng s·ªë records
        result = session.execute("SELECT COUNT(*) FROM realtime_data")
        total_count = result.one()[0]
        print_info(f"T·ªïng s·ªë records: {total_count}")
        
        if total_count == 0:
            print_warning("KH√îNG c√≥ d·ªØ li·ªáu trong Cassandra!")
            cluster.shutdown()
            return False
        
        # L·∫•y 5 records m·ªõi nh·∫•t
        result = session.execute("""
            SELECT datetime, pm25, aqi, quality, processed_at 
            FROM realtime_data 
            LIMIT 5
        """)
        
        print_info("\n5 records m·ªõi nh·∫•t:")
        records = list(result)
        for i, row in enumerate(records, 1):
            print(f"  {i}. datetime={row.datetime}, pm25={row.pm25:.2f}, aqi={row.aqi}, quality={row.quality}, processed_at={row.processed_at}")
        
        # L·∫•y record m·ªõi nh·∫•t v√† c≈© nh·∫•t (Cassandra kh√¥ng h·ªó tr·ª£ ORDER BY tr√™n non-primary key)
        # S·∫Ω sort trong Python
        result = session.execute("""
            SELECT datetime, pm25, aqi, quality, processed_at 
            FROM realtime_data 
            LIMIT 1000
        """)
        
        all_records = list(result)
        if all_records:
            # Sort theo datetime trong Python
            all_records.sort(key=lambda x: x.datetime, reverse=True)
            latest = all_records[0]
            print_info(f"\nRecord m·ªõi nh·∫•t:")
            print(f"  datetime: {latest.datetime}")
            print(f"  pm25: {latest.pm25:.2f}")
            print(f"  aqi: {latest.aqi}")
            print(f"  quality: {latest.quality}")
            print(f"  processed_at: {latest.processed_at}")
            
            all_records.sort(key=lambda x: x.datetime, reverse=False)
            oldest = all_records[0]
            print_info(f"\nRecord c≈© nh·∫•t:")
            print(f"  datetime: {oldest.datetime}")
            print(f"  pm25: {oldest.pm25:.2f}")
            print(f"  aqi: {oldest.aqi}")
            print(f"  quality: {oldest.quality}")
            print(f"  processed_at: {oldest.processed_at}")
        
        # Ki·ªÉm tra d·ªØ li·ªáu c√≥ ƒë∆∞·ª£c c·∫≠p nh·∫≠t g·∫ßn ƒë√¢y kh√¥ng (trong 1 ph√∫t qua)
        current_time = datetime.now()
        if latest and latest.processed_at:
            time_diff = (current_time - latest.processed_at.replace(tzinfo=None)).total_seconds()
            if time_diff < 60:
                print_success(f"D·ªØ li·ªáu ƒë∆∞·ª£c c·∫≠p nh·∫≠t {time_diff:.0f} gi√¢y tr∆∞·ªõc (realtime)")
            else:
                print_warning(f"D·ªØ li·ªáu ƒë∆∞·ª£c c·∫≠p nh·∫≠t {time_diff:.0f} gi√¢y tr∆∞·ªõc (KH√îNG realtime - qu√° c≈©)")
        
        cluster.shutdown()
        return True
    except Exception as e:
        print_error(f"L·ªói khi ki·ªÉm tra d·ªØ li·ªáu Cassandra: {e}")
        import traceback
        print_error(f"Traceback: {traceback.format_exc()}")
        return False

def check_dashboard_connection():
    """Ki·ªÉm tra k·∫øt n·ªëi t·ª´ Dashboard ƒë·∫øn Cassandra"""
    print_header("7. KI·ªÇM TRA DASHBOARD CONNECTION")
    
    try:
        # Simulate dashboard connection
        cluster = Cluster(['localhost'], port=9042)
        session = cluster.connect()
        session.set_keyspace('air_quality')
        
        # Query gi·ªëng nh∆∞ dashboard
        query = """
        SELECT datetime, pm25, aqi, quality, processed_at 
        FROM realtime_data
        LIMIT 1000
        """
        rows = session.execute(query)
        
        data = []
        for row in rows:
            data.append({
                'datetime': row.datetime,
                'pm25': row.pm25,
                'aqi': row.aqi,
                'quality': row.quality,
                'processed_at': row.processed_at
            })
        
        print_success(f"Dashboard c√≥ th·ªÉ ƒë·ªçc ƒë∆∞·ª£c {len(data)} records")
        
        if len(data) > 0:
            # Convert datetime
            import pandas as pd
            df = pd.DataFrame(data)
            df['datetime'] = pd.to_datetime(df['datetime'])
            df = df.sort_values('datetime', ascending=False)
            
            latest = df.iloc[0]
            print_info(f"\nRecord m·ªõi nh·∫•t m√† Dashboard s·∫Ω hi·ªÉn th·ªã:")
            print(f"  datetime: {latest['datetime']}")
            print(f"  pm25: {latest['pm25']:.2f}")
            print(f"  aqi: {latest['aqi']}")
            print(f"  quality: {latest['quality']}")
        
        cluster.shutdown()
        return True
    except Exception as e:
        print_error(f"L·ªói khi ki·ªÉm tra Dashboard connection: {e}")
        import traceback
        print_error(f"Traceback: {traceback.format_exc()}")
        return False

def check_streamlit():
    """Ki·ªÉm tra Streamlit c√≥ ƒëang ch·∫°y kh√¥ng"""
    print_header("8. KI·ªÇM TRA STREAMLIT DASHBOARD")
    
    try:
        result = subprocess.run(
            ['ps', 'aux'],
            capture_output=True,
            text=True,
            check=True
        )
        
        streamlit_running = False
        for line in result.stdout.split('\n'):
            if 'streamlit' in line.lower() and 'streamlit_app.py' in line:
                streamlit_running = True
                parts = line.split()
                pid = parts[1]
                print_success(f"Streamlit Dashboard ƒëang ch·∫°y (PID: {pid})")
                print_info(f"Command: {' '.join(parts[10:])}")
                break
        
        if not streamlit_running:
            print_warning("Streamlit Dashboard KH√îNG ƒëang ch·∫°y!")
            print_info("Ch·∫°y: streamlit run dashboard/streamlit_app.py")
        
        return streamlit_running
    except Exception as e:
        print_error(f"L·ªói khi ki·ªÉm tra Streamlit: {e}")
        return False

def monitor_data_updates():
    """Monitor d·ªØ li·ªáu c√≥ ƒë∆∞·ª£c c·∫≠p nh·∫≠t kh√¥ng trong 30 gi√¢y"""
    print_header("9. MONITOR D·ªÆ LI·ªÜU C·∫¨P NH·∫¨T (30 gi√¢y)")
    
    try:
        cluster = Cluster(['localhost'], port=9042)
        session = cluster.connect('air_quality')
        
        # L·∫•y s·ªë l∆∞·ª£ng records ban ƒë·∫ßu
        result = session.execute("SELECT COUNT(*) FROM realtime_data")
        initial_count = result.one()[0]
        print_info(f"S·ªë l∆∞·ª£ng records ban ƒë·∫ßu: {initial_count}")
        
        # L·∫•y record m·ªõi nh·∫•t ban ƒë·∫ßu
        result = session.execute("""
            SELECT datetime, processed_at 
            FROM realtime_data 
            ORDER BY datetime DESC 
            LIMIT 1
        """)
        initial_latest = result.one()
        if initial_latest:
            print_info(f"Record m·ªõi nh·∫•t ban ƒë·∫ßu: {initial_latest.datetime}, processed_at: {initial_latest.processed_at}")
        
        print_info("ƒêang monitor trong 30 gi√¢y...")
        time.sleep(30)
        
        # Ki·ªÉm tra l·∫°i
        result = session.execute("SELECT COUNT(*) FROM realtime_data")
        final_count = result.one()[0]
        print_info(f"S·ªë l∆∞·ª£ng records sau 30 gi√¢y: {final_count}")
        
        result = session.execute("""
            SELECT datetime, processed_at 
            FROM realtime_data 
            ORDER BY datetime DESC 
            LIMIT 1
        """)
        final_latest = result.one()
        if final_latest:
            print_info(f"Record m·ªõi nh·∫•t sau 30 gi√¢y: {final_latest.datetime}, processed_at: {final_latest.processed_at}")
        
        # So s√°nh
        if final_count > initial_count:
            print_success(f"C√≥ {final_count - initial_count} records m·ªõi ƒë∆∞·ª£c th√™m v√†o!")
        elif final_latest and initial_latest and final_latest.datetime != initial_latest.datetime:
            print_success("C√≥ d·ªØ li·ªáu m·ªõi ƒë∆∞·ª£c c·∫≠p nh·∫≠t!")
        else:
            print_warning("KH√îNG c√≥ d·ªØ li·ªáu m·ªõi ƒë∆∞·ª£c th√™m v√†o trong 30 gi√¢y!")
            print_warning("C√≥ th·ªÉ Producer ho·∫∑c Spark Streaming kh√¥ng ho·∫°t ƒë·ªông ƒë√∫ng!")
        
        cluster.shutdown()
        return True
    except Exception as e:
        print_error(f"L·ªói khi monitor: {e}")
        import traceback
        print_error(f"Traceback: {traceback.format_exc()}")
        return False

def generate_report():
    """T·∫°o b√°o c√°o t·ªïng h·ª£p"""
    print_header("üìä B√ÅO C√ÅO T·ªîNG H·ª¢P")
    
    results = {
        'docker': check_docker_services(),
        'kafka_topic': check_kafka_topic(),
        'kafka_producer': check_kafka_producer(),
        'spark_streaming': check_spark_streaming(),
        'cassandra_connection': check_cassandra_connection(),
        'cassandra_data': check_cassandra_data(),
        'dashboard_connection': check_dashboard_connection(),
        'streamlit': check_streamlit(),
    }
    
    print("\n" + "="*60)
    print("K·∫æT QU·∫¢ KI·ªÇM TRA:")
    print("="*60)
    
    for component, status in results.items():
        if status:
            print_success(f"{component}: OK")
        else:
            print_error(f"{component}: FAILED")
    
    all_ok = all(results.values())
    
    if all_ok:
        print_success("\n‚úÖ T·∫§T C·∫¢ COMPONENTS ƒêANG HO·∫†T ƒê·ªòNG!")
    else:
        print_error("\n‚ùå M·ªòT S·ªê COMPONENTS C√ì V·∫§N ƒê·ªÄ!")
        print_info("\nC√°c b∆∞·ªõc kh·∫Øc ph·ª•c:")
        if not results['docker']:
            print_info("  1. Kh·ªüi ƒë·ªông Docker services: cd docker && docker-compose up -d")
        if not results['kafka_topic']:
            print_info("  2. T·∫°o Kafka topic: bash scripts/create_topics.sh")
        if not results['kafka_producer']:
            print_info("  3. Ch·∫°y Producer: python kafka/producer.py")
        if not results['spark_streaming']:
            print_info("  4. Ch·∫°y Spark Streaming: bash run_spark_cassandra.sh")
        if not results['cassandra_connection'] or not results['cassandra_data']:
            print_info("  5. Kh·ªüi t·∫°o Cassandra schema: docker exec -it cassandra cqlsh -f /scripts/init_cassandra.cql")
        if not results['streamlit']:
            print_info("  6. Ch·∫°y Dashboard: streamlit run dashboard/streamlit_app.py")
    
    return results

def main():
    """Main function"""
    print(f"\n{Colors.BOLD}{Colors.BLUE}")
    print("="*60)
    print("  AIR QUALITY STREAMING SYSTEM - DEBUG TOOL")
    print("="*60)
    print(f"{Colors.RESET}\n")
    
    print_info(f"Th·ªùi gian ch·∫°y: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Ch·∫°y c√°c ki·ªÉm tra
    results = generate_report()
    
    # H·ªèi c√≥ mu·ªën monitor kh√¥ng
    print("\n" + "="*60)
    response = input("B·∫°n c√≥ mu·ªën monitor d·ªØ li·ªáu c·∫≠p nh·∫≠t trong 30 gi√¢y? (y/n): ")
    if response.lower() == 'y':
        monitor_data_updates()
    
    print(f"\n{Colors.BOLD}{Colors.BLUE}")
    print("="*60)
    print("  DEBUG HO√ÄN T·∫§T")
    print("="*60)
    print(f"{Colors.RESET}\n")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nƒê√£ d·ª´ng debug tool.")
        sys.exit(0)
    except Exception as e:
        print_error(f"L·ªói kh√¥ng mong ƒë·ª£i: {e}")
        import traceback
        print_error(traceback.format_exc())
        sys.exit(1)

