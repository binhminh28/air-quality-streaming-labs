# TÃŠN Dá»° ÃN: Há»† THá»NG GIÃM SÃT CHáº¤T LÆ¯á»¢NG KHÃ”NG KHÃ THá»œI GIAN THá»°C (REAL-TIME AIR QUALITY MONITORING SYSTEM)

## 1. Giá»›i thiá»‡u tá»•ng quan

Dá»± Ã¡n nÃ y lÃ  má»™t há»‡ thá»‘ng xá»­ lÃ½ dá»¯ liá»‡u lá»›n (Big Data) Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ giÃ¡m sÃ¡t, phÃ¢n tÃ­ch vÃ  cáº£nh bÃ¡o cháº¥t lÆ°á»£ng khÃ´ng khÃ­ theo thá»i gian thá»±c. Há»‡ thá»‘ng mÃ´ phá»ng trá»n váº¹n quy trÃ¬nh ká»¹ thuáº­t dá»¯ liá»‡u (Data Engineering) tá»« khÃ¢u thu tháº­p, xá»­ lÃ½ Ä‘áº¿n hiá»ƒn thá»‹, Ã¡p dá»¥ng cÃ¡c tiÃªu chuáº©n tÃ­nh toÃ¡n chá»‰ sá»‘ AQI thá»±c táº¿ cá»§a Viá»‡t Nam (QCVN 05:2013/BTNMT).

Há»‡ thá»‘ng Ä‘Æ°á»£c xÃ¢y dá»±ng Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n cá»‘t lÃµi cá»§a Big Data, thá»a mÃ£n mÃ´ hÃ¬nh 3V:

* **Volume (Khá»‘i lÆ°á»£ng):** Kháº£ nÄƒng xá»­ lÃ½ lÆ°á»£ng lá»›n dá»¯ liá»‡u log tá»« cÃ¡c tráº¡m quan tráº¯c (Ä‘Æ°á»£c mÃ´ phá»ng).
* **Velocity (Tá»‘c Ä‘á»™):** YÃªu cáº§u xá»­ lÃ½ vÃ  tÃ­nh toÃ¡n chá»‰ sá»‘ AQI gáº§n nhÆ° tá»©c thá»i (Real-time) ngay khi dá»¯ liá»‡u Ä‘Æ°á»£c sinh ra.
* **Variety (Äa dáº¡ng):** Xá»­ lÃ½ dá»¯ liá»‡u há»—n há»£p gá»“m chuá»—i thá»i gian (time-series), cÃ¡c chá»‰ sá»‘ hÃ³a há»c (PM2.5, PM10, v.v.) vÃ  thÃ´ng tin Ä‘á»‹nh danh tráº¡m.

---

## 2. Kiáº¿n trÃºc há»‡ thá»‘ng (System Architecture)

Dá»± Ã¡n Ã¡p dá»¥ng kiáº¿n trÃºc **Stream Processing Pipeline** hiá»‡n Ä‘áº¡i, Ä‘áº£m báº£o tÃ­nh á»•n Ä‘á»‹nh vÃ  kháº£ nÄƒng má»Ÿ rá»™ng. Há»‡ thá»‘ng bao gá»“m 4 táº§ng chÃ­nh:

**Táº§ng 1: Thu tháº­p dá»¯ liá»‡u (Ingestion Layer)**

* **CÃ´ng nghá»‡:** Apache Kafka.
* **Chá»©c nÄƒng:** ÄÃ³ng vai trÃ² lÃ  bá»™ Ä‘á»‡m trung gian (Message Broker). Kafka tiáº¿p nháº­n dá»¯ liá»‡u thÃ´ tá»« cÃ¡c tráº¡m cáº£m biáº¿n (Producer) vÃ  lÆ°u trá»¯ táº¡m thá»i. Viá»‡c sá»­ dá»¥ng Kafka giÃºp tÃ¡ch biá»‡t (decouple) nguá»“n phÃ¡t dá»¯ liá»‡u vÃ  bá»™ xá»­ lÃ½, Ä‘áº£m báº£o há»‡ thá»‘ng khÃ´ng bá»‹ ngháº½n (backpressure) khi lÆ°u lÆ°á»£ng dá»¯ liá»‡u tÄƒng Ä‘á»™t biáº¿n.

**Táº§ng 2: Xá»­ lÃ½ dá»¯ liá»‡u (Processing Layer)**

* **CÃ´ng nghá»‡:** Apache Spark Structured Streaming.
* **Chá»©c nÄƒng:** ÄÃ¢y lÃ  "bá»™ nÃ£o" cá»§a há»‡ thá»‘ng. Spark Ä‘á»c dá»¯ liá»‡u liÃªn tá»¥c tá»« Kafka, thá»±c hiá»‡n viá»‡c lÃ m sáº¡ch, kiá»ƒm tra Ä‘á»‹nh dáº¡ng (Schema validation) vÃ  Ã¡p dá»¥ng thuáº­t toÃ¡n tÃ­nh toÃ¡n AQI. Spark hoáº¡t Ä‘á»™ng theo cÆ¡ cháº¿ Micro-batch, giÃºp cÃ¢n báº±ng giá»¯a Ä‘á»™ trá»… tháº¥p vÃ  nÄƒng lá»±c xá»­ lÃ½ lÆ°á»£ng lá»›n dá»¯ liá»‡u.

**Táº§ng 3: LÆ°u trá»¯ (Storage Layer)**

* **CÃ´ng nghá»‡:** Apache Cassandra.
* **Chá»©c nÄƒng:** LÆ°u trá»¯ dá»¯ liá»‡u sau khi Ä‘Ã£ xá»­ lÃ½. Cassandra Ä‘Æ°á»£c lá»±a chá»n vÃ¬ Ä‘Ã¢y lÃ  cÆ¡ sá»Ÿ dá»¯ liá»‡u NoSQL tá»‘i Æ°u cho viá»‡c ghi dá»¯ liá»‡u liÃªn tá»¥c vá»›i tá»‘c Ä‘á»™ cao (Write-heavy) vÃ  truy váº¥n theo chuá»—i thá»i gian, phÃ¹ há»£p vá»›i Ä‘áº·c thÃ¹ dá»¯ liá»‡u cáº£m biáº¿n.

**Táº§ng 4: Hiá»ƒn thá»‹ & Cáº£nh bÃ¡o (Serving Layer)**

* **CÃ´ng nghá»‡:** Streamlit & WebSocket.
* **Chá»©c nÄƒng:** Cung cáº¥p giao diá»‡n trá»±c quan cho ngÆ°á»i dÃ¹ng cuá»‘i. Dashboard káº¿t ná»‘i qua WebSocket Ä‘á»ƒ nháº­n dá»¯ liá»‡u má»›i nháº¥t tá»« há»‡ thá»‘ng vÃ  váº½ biá»ƒu Ä‘á»“ biáº¿n thiÃªn cháº¥t lÆ°á»£ng khÃ´ng khÃ­, Ä‘á»“ng thá»i hiá»ƒn thá»‹ cáº£nh bÃ¡o mÃ u sáº¯c tÆ°Æ¡ng á»©ng vá»›i má»©c Ä‘á»™ Ã´ nhiá»…m.

---

## 3. Luá»“ng dá»¯ liá»‡u (Data Flow)

HÃ nh trÃ¬nh cá»§a má»™t gÃ³i tin dá»¯ liá»‡u trong há»‡ thá»‘ng diá»…n ra qua 5 bÆ°á»›c cháº·t cháº½:

**1. MÃ´ phá»ng nguá»“n tin (Simulation Source):**
* ChÆ°Æ¡ng trÃ¬nh `producer.py` Ä‘á»c tuáº§n tá»± cÃ¡c dÃ²ng dá»¯ liá»‡u lá»‹ch sá»­ tá»« file Parquet.
* NÃ³ Ä‘Ã³ng vai trÃ² nhÆ° má»™t "Sensor áº£o", chÃ¨n timestamp hiá»‡n táº¡i vÃ o báº£n ghi Ä‘á»ƒ giáº£ láº­p dá»¯ liá»‡u má»›i Ä‘Æ°á»£c sinh ra ngay tá»©c thÃ¬ (Real-time injection).


**2. Äá»‡m dá»¯ liá»‡u (Message Queuing):**
* Dá»¯ liá»‡u Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i (Serialize) sang Ä‘á»‹nh dáº¡ng JSON vÃ  Ä‘áº©y vÃ o Kafka topic `air_quality_realtime`.
* Kafka giá»¯ vai trÃ² bá»™ Ä‘á»‡m, Ä‘áº£m báº£o dá»¯ liá»‡u khÃ´ng bá»‹ máº¥t náº¿u bá»™ xá»­ lÃ½ phÃ­a sau bá»‹ quÃ¡ táº£i.


**3. Xá»­ lÃ½ luá»“ng (Stream Processing):**
* Spark Streaming Job (`streaming_job.py`) liÃªn tá»¥c láº¯ng nghe Topic.
* **Parse & Validate:** Chuyá»ƒn Ä‘á»•i JSON binary thÃ nh DataFrame cÃ³ cáº¥u trÃºc (Schema) Ä‘á»‹nh sáºµn.
* **Business Logic:** Ãp dá»¥ng UDF Ä‘á»ƒ tÃ­nh AQI cho tá»«ng chá»‰ sá»‘ (PM2.5, PM10), sau Ä‘Ã³ dÃ¹ng thuáº­t toÃ¡n `max()` Ä‘á»ƒ láº¥y chá»‰ sá»‘ AQI tá»•ng há»£p cuá»‘i cÃ¹ng theo chuáº©n QCVN 05:2013.
* **GÃ¡n nhÃ£n:** PhÃ¢n loáº¡i cháº¥t lÆ°á»£ng (Tá»‘t/Trung bÃ¬nh/KÃ©m...) dá»±a trÃªn chá»‰ sá»‘ AQI vá»«a tÃ­nh.


**4. LÆ°u trá»¯ (Persistence):**
* Spark gom cÃ¡c káº¿t quáº£ xá»­ lÃ½ láº¡i vÃ  sá»­ dá»¥ng ká»¹ thuáº­t `foreachBatch` Ä‘á»ƒ ghi hÃ ng loáº¡t (Bulk Insert) vÃ o báº£ng `realtime_data` trong Cassandra.


**5. PhÃ¢n phá»‘i & Hiá»ƒn thá»‹ (Serving & Visualization):**
* **API Layer (Quan trá»ng):** Má»™t `websocket_server.py` cháº¡y ngáº§m, Ä‘Ã³ng vai trÃ² lÃ  Backend API. NÃ³ thá»±c hiá»‡n cÃ¡c truy váº¥n hiá»‡u quáº£ vÃ o Cassandra Ä‘á»ƒ láº¥y dá»¯ liá»‡u má»›i nháº¥t (Top N records).
* **Frontend:** á»¨ng dá»¥ng `streamlit_app.py` hoáº¡t Ä‘á»™ng theo cÆ¡ cháº¿ Polling (Ä‘á»‹nh ká»³ gá»­i request) tá»›i API Server trÃªn Ä‘á»ƒ láº¥y dá»¯ liá»‡u JSON vÃ  váº½ láº¡i biá»ƒu Ä‘á»“ mÃ  khÃ´ng cáº§n táº£i láº¡i trang.

---

## 4. CÃ¡c khÃ¡i niá»‡m & Quyáº¿t Ä‘á»‹nh ká»¹ thuáº­t quan trá»ng

Trong quÃ¡ trÃ¬nh xÃ¢y dá»±ng, nhÃ³m phÃ¡t triá»ƒn Ä‘Ã£ Ä‘Æ°a ra cÃ¡c quyáº¿t Ä‘á»‹nh ká»¹ thuáº­t dá»±a trÃªn Ä‘áº·c thÃ¹ cá»§a dá»± Ã¡n:

**Táº¡i sao chá»n Parquet thay vÃ¬ CSV Ä‘á»ƒ giáº£ láº­p dá»¯ liá»‡u?**
Parquet lÃ  Ä‘á»‹nh dáº¡ng lÆ°u trá»¯ dáº¡ng cá»™t (Columnar Storage). Trong mÃ´i trÆ°á»ng Big Data, Parquet cho tá»‘c Ä‘á»™ Ä‘á»c nhanh hÆ¡n CSV gáº¥p nhiá»u láº§n vÃ  quan trá»ng hÆ¡n lÃ  nÃ³ giá»¯ nguyÃªn Ä‘Æ°á»£c kiá»ƒu dá»¯ liá»‡u (Schema). Äiá»u nÃ y giÃºp viá»‡c mÃ´ phá»ng dá»¯ liá»‡u Ä‘áº§u vÃ o chÃ­nh xÃ¡c vÃ  hiá»‡u quáº£ hÆ¡n.

**Táº¡i sao sá»­ dá»¥ng Spark Structured Streaming?**
Thay vÃ¬ mÃ´ hÃ¬nh Streaming cÅ© (DStream), Structured Streaming cho phÃ©p lÃ m viá»‡c vá»›i dá»¯ liá»‡u stream nhÆ° má»™t báº£ng vÃ´ háº¡n (Unbounded Table). Äiá»u nÃ y giÃºp code dá»… Ä‘á»c hÆ¡n, dá»… báº£o trÃ¬ hÆ¡n vÃ  táº­n dá»¥ng Ä‘Æ°á»£c sá»©c máº¡nh tá»‘i Æ°u hÃ³a cá»§a Spark SQL Engine. NgoÃ i ra, nÃ³ há»— trá»£ "Exactly-once semantics", Ä‘áº£m báº£o má»—i báº£n ghi chá»‰ Ä‘Æ°á»£c xá»­ lÃ½ Ä‘Ãºng má»™t láº§n, trÃ¡nh sai lá»‡ch sá»‘ liá»‡u.

**CÆ¡ cháº¿ tÃ­nh toÃ¡n AQI (QCVN 05:2013/BTNMT)**
Há»‡ thá»‘ng khÃ´ng sá»­ dá»¥ng cÃ´ng thá»©c AQI cá»§a Má»¹ hay ChÃ¢u Ã‚u mÃ  Ã¡p dá»¥ng Quy chuáº©n ká»¹ thuáº­t quá»‘c gia cá»§a Viá»‡t Nam. CÃ´ng thá»©c nÃ y tÃ­nh toÃ¡n dá»±a trÃªn ná»“ng Ä‘á»™ bá»¥i trong khoáº£ng thá»i gian nháº¥t Ä‘á»‹nh, sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p ná»™i suy tuyáº¿n tÃ­nh giá»¯a cÃ¡c Ä‘iá»ƒm cáº­n (breakpoints) Ä‘á»ƒ ra chá»‰ sá»‘ cuá»‘i cÃ¹ng.

---

## 5. HÆ°á»›ng dáº«n cÃ i Ä‘áº·t vÃ  váº­n hÃ nh (Automated Deployment)

Há»‡ thá»‘ng sá»­ dá»¥ng cÃ¡c script tá»± Ä‘á»™ng hÃ³a Ä‘á»ƒ Ä‘Æ¡n giáº£n hÃ³a quy trÃ¬nh. Quy trÃ¬nh chuáº©n bao gá»“m 3 giai Ä‘oáº¡n: **Háº¡ táº§ng -> Khá»Ÿi táº¡o -> á»¨ng dá»¥ng**.

### YÃªu cáº§u tiÃªn quyáº¿t (Prerequisites)

* **Docker & Docker Compose** (Ä‘Ã£ cÃ i Ä‘áº·t).
* **Python 3.8+** (Ä‘Ã£ táº¡o mÃ´i trÆ°á»ng áº£o `.venv`).

### Quy trÃ¬nh khá»Ÿi cháº¡y

**BÆ°á»›c 1: Khá»Ÿi Ä‘á»™ng Háº¡ táº§ng (Infrastructure)**
TrÆ°á»›c háº¿t, cáº§n dá»±ng cÃ¡c container Kafka, Zookeeper vÃ  Cassandra. Script khá»Ÿi cháº¡y á»©ng dá»¥ng sáº½ tháº¥t báº¡i náº¿u bÆ°á»›c nÃ y chÆ°a hoÃ n táº¥t.

```bash
# Di chuyá»ƒn vÃ o thÆ° má»¥c docker
cd docker
docker-compose up -d
# Quay láº¡i thÆ° má»¥c gá»‘c
cd ..

```

**BÆ°á»›c 2: Khá»Ÿi táº¡o Dá»¯ liá»‡u (Setup Data)**
Chá» khoáº£ng 30-60 giÃ¢y Ä‘á»ƒ Cassandra khá»Ÿi Ä‘á»™ng xong, sau Ä‘Ã³ cháº¡y cÃ¡c lá»‡nh sau Ä‘á»ƒ táº¡o Topic vÃ  Báº£ng dá»¯ liá»‡u:

```bash
# 1. Táº¡o Kafka Topic
bash scripts/create_topics.sh

# 2. Khá»Ÿi táº¡o Cassandra Schema
docker exec -it cassandra cqlsh -f /scripts/init_cassandra.cql

```

**BÆ°á»›c 3: Khá»Ÿi cháº¡y á»¨ng dá»¥ng (Start Backend)**
Sá»­ dá»¥ng script `start_all.sh`. Script nÃ y sáº½ tá»± Ä‘á»™ng cháº¡y ngáº§m (background) 3 dá»‹ch vá»¥ cá»‘t lÃµi:

1. **WebSocket Server**: Cáº§u ná»‘i dá»¯ liá»‡u cho Dashboard.
2. **Producer**: Báº¯t Ä‘áº§u mÃ´ phá»ng gá»­i dá»¯ liá»‡u sensor.
3. **Spark Streaming**: Báº¯t Ä‘áº§u xá»­ lÃ½ luá»“ng dá»¯ liá»‡u vÃ  ghi vÃ o DB.

```bash
bash start_all.sh

```

*Báº¡n cÃ³ thá»ƒ kiá»ƒm tra tráº¡ng thÃ¡i cÃ¡c dá»‹ch vá»¥ qua file log trong thÆ° má»¥c `logs/`.*

**BÆ°á»›c 4: Má»Ÿ Dashboard (Frontend)**
Cuá»‘i cÃ¹ng, khá»Ÿi cháº¡y giao diá»‡n ngÆ°á»i dÃ¹ng Streamlit:

```bash
streamlit run dashboard/streamlit_app.py

```

*Truy cáº­p Dashboard táº¡i:* `http://localhost:8501`

---

### CÃ¡ch dá»«ng há»‡ thá»‘ng

Äá»ƒ dá»«ng táº¥t cáº£ cÃ¡c tiáº¿n trÃ¬nh Python (Producer, Spark, WebSocket) vÃ  dá»n dáº¹p PID:

```bash
bash stop_all.sh

```

*LÆ°u Ã½: Lá»‡nh nÃ y khÃ´ng táº¯t Docker containers. Náº¿u muá»‘n táº¯t háº³n háº¡ táº§ng, hÃ£y dÃ¹ng `docker-compose down` trong thÆ° má»¥c docker.*

---

## 6. Cáº¥u trÃºc thÆ° má»¥c dá»± Ã¡n (Project Structure)

Dá»± Ã¡n Ä‘Æ°á»£c tá»• chá»©c theo tá»«ng module chá»©c nÄƒng, tÃ¡ch biá»‡t rÃµ rÃ ng giá»¯a cáº¥u hÃ¬nh háº¡ táº§ng, mÃ£ nguá»“n xá»­ lÃ½ vÃ  giao diá»‡n ngÆ°á»i dÃ¹ng.

```text
air-quality-streaming-labs/
â”‚
â”œâ”€â”€ ğŸ“‚ data/                        # Chá»©a dá»¯ liá»‡u Ä‘áº§u vÃ o cho mÃ´ phá»ng
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ air_quality_merged.parquet  # File Parquet chá»©a dá»¯ liá»‡u lá»‹ch sá»­ Ä‘Ã£ lÃ m sáº¡ch, dÃ¹ng Ä‘á»ƒ giáº£ láº­p stream
â”‚
â”œâ”€â”€ ğŸ“‚ docker/                      # Cáº¥u hÃ¬nh háº¡ táº§ng container hÃ³a
â”‚   â””â”€â”€ docker-compose.yml          # Äá»‹nh nghÄ©a cÃ¡c service: Kafka, Zookeeper, Cassandra
â”‚
â”œâ”€â”€ ğŸ“‚ kafka/                       # Module Ingestion (Thu tháº­p dá»¯ liá»‡u)
â”‚   â”œâ”€â”€ producer.py                 # Script Python Ä‘á»c file Parquet vÃ  gá»­i message vÃ o Kafka (giáº£ láº­p sensor)
â”‚   â””â”€â”€ consumer.py                 # Script debug Ä‘á»ƒ kiá»ƒm tra xem dá»¯ liá»‡u Ä‘Ã£ vÃ o Kafka chÆ°a
â”‚
â”œâ”€â”€ ğŸ“‚ spark/                       # Module Processing (Xá»­ lÃ½ dá»¯ liá»‡u)
â”‚   â”œâ”€â”€ streaming_job.py            # Spark Job chÃ­nh: Äá»c Kafka -> TÃ­nh AQI -> Ghi xuá»‘ng Cassandra
â”‚   â””â”€â”€ sink_cassandra.py           # Module há»— trá»£ ghi dá»¯ liá»‡u vÃ o Cassandra (Batch writer)
â”‚
â”œâ”€â”€ ğŸ“‚ dashboard/                   # Module Visualization (Hiá»ƒn thá»‹)
â”‚   â”œâ”€â”€ streamlit_app.py            # á»¨ng dá»¥ng Web hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ vÃ  cáº£nh bÃ¡o Real-time
â”‚   â”œâ”€â”€ websocket_server.py         # Server trung gian chuyá»ƒn tiáº¿p dá»¯ liá»‡u tá»« Backend lÃªn Frontend
â”‚   â””â”€â”€ README.md                   # HÆ°á»›ng dáº«n riÃªng cho pháº§n Dashboard
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                     # CÃ¡c cÃ´ng cá»¥ tiá»‡n Ã­ch (Utilities) & Setup
â”‚   â”œâ”€â”€ create_topics.sh            # Script táº¡o Kafka topic (air_quality_realtime)
â”‚   â”œâ”€â”€ init_cassandra.cql          # Script CQL khá»Ÿi táº¡o Keyspace vÃ  Table trong Cassandra
â”‚   â”œâ”€â”€ update_cassandra_schema.sh  # Script cáº­p nháº­t schema DB khi cÃ³ thay Ä‘á»•i
â”‚   â”œâ”€â”€ data_preprocessing.py       # Script tiá»n xá»­ lÃ½ dá»¯ liá»‡u thÃ´ ban Ä‘áº§u (ETL offline)
â”‚   â””â”€â”€ debug_system.py             # Script kiá»ƒm tra sá»©c khá»e há»‡ thá»‘ng (Health check)
â”‚
â”œâ”€â”€ ğŸ“‚ logs/                        # NÆ¡i lÆ°u trá»¯ log hoáº¡t Ä‘á»™ng cá»§a há»‡ thá»‘ng
â”‚   â”œâ”€â”€ spark_streaming.log         # Log lá»—i vÃ  tráº¡ng thÃ¡i cá»§a Spark Job
â”‚   â””â”€â”€ websocket_server.log        # Log káº¿t ná»‘i cá»§a Dashboard
â”‚
â”œâ”€â”€ ğŸ“œ CÃ¡c file quáº£n lÃ½ & khá»Ÿi cháº¡y (Root)
â”‚   â”œâ”€â”€ start_all.sh                # "One-click" script: Khá»Ÿi Ä‘á»™ng Docker vÃ  táº¡o mÃ´i trÆ°á»ng
â”‚   â”œâ”€â”€ stop_all.sh                 # Dá»«ng vÃ  dá»n dáº¹p toÃ n bá»™ há»‡ thá»‘ng
â”‚   â”œâ”€â”€ run_spark_cassandra.sh      # Lá»‡nh submit Spark Job lÃªn cluster
â”‚   â”œâ”€â”€ run_dashboard.sh            # Lá»‡nh khá»Ÿi cháº¡y Streamlit Dashboard
â”‚   â”œâ”€â”€ run_websocket_server.sh     # Lá»‡nh khá»Ÿi cháº¡y WebSocket Server
â”‚   â”œâ”€â”€ pyproject.toml              # Quáº£n lÃ½ dependencies (thÆ° viá»‡n Python) báº±ng Poetry
â”‚   â””â”€â”€ poetry.lock                 # File khÃ³a phiÃªn báº£n thÆ° viá»‡n Ä‘á»ƒ Ä‘áº£m báº£o Ä‘á»“ng bá»™ mÃ´i trÆ°á»ng

```

### Giáº£i thÃ­ch chi tiáº¿t cÃ¡c thÃ nh pháº§n chÃ­nh:

1. **`docker/docker-compose.yml`**: ÄÃ¢y lÃ  báº£n thiáº¿t káº¿ háº¡ táº§ng. NÃ³ quy Ä‘á»‹nh Kafka cháº¡y port 9092, Cassandra cháº¡y port 9042 vÃ  Zookeeper quáº£n lÃ½ Kafka.
2. **`kafka/producer.py`**: Thay vÃ¬ chá» dá»¯ liá»‡u tá»« thiáº¿t bá»‹ tháº­t, file nÃ y Ä‘Ã³ng vai trÃ² "mÃ¡y phÃ¡t", Ä‘á»c dá»¯ liá»‡u lá»‹ch sá»­ tá»« folder `data/` vÃ  báº¯n vÃ o há»‡ thá»‘ng vá»›i tá»‘c Ä‘á»™ tÃ¹y chá»‰nh (vÃ­ dá»¥: 1 giÃ¢y/báº£n ghi) Ä‘á»ƒ test kháº£ nÄƒng chá»‹u táº£i.
3. **`spark/streaming_job.py`**: TrÃ¡i tim cá»§a há»‡ thá»‘ng. File nÃ y chá»©a logic nghiá»‡p vá»¥:
* Äá»‹nh nghÄ©a Schema cho dá»¯ liá»‡u JSON Ä‘áº§u vÃ o.
* Chá»©a hÃ m UDF (User Defined Function) Ä‘á»ƒ tÃ­nh toÃ¡n chá»‰ sá»‘ AQI theo chuáº©n Viá»‡t Nam.
* Äiá»u phá»‘i luá»“ng dá»¯ liá»‡u tá»« Kafka sang Cassandra.


4. **`scripts/init_cassandra.cql`**: File Ä‘á»‹nh nghÄ©a cáº¥u trÃºc dá»¯ liá»‡u lÆ°u trá»¯ (Data Model). NÃ³ táº¡o báº£ng `realtime_data` vá»›i khÃ³a chÃ­nh phÃ¹ há»£p cho viá»‡c truy váº¥n theo thá»i gian.
5. **`start_all.sh`**: Script tá»± Ä‘á»™ng hÃ³a quy trÃ¬nh triá»ƒn khai (DevOps), giÃºp ngÆ°á»i dÃ¹ng má»›i khÃ´ng cáº§n gÃµ tá»«ng lá»‡nh Docker phá»©c táº¡p mÃ  chá»‰ cáº§n cháº¡y má»™t file duy nháº¥t Ä‘á»ƒ dá»±ng mÃ´i trÆ°á»ng.