import polars as pl
from kafka import KafkaProducer
import json
import time
import os
import argparse
import sys
from datetime import datetime, timezone

# C·∫•u h√¨nh m·∫∑c ƒë·ªãnh
DEFAULT_TOPIC = "air_quality_realtime"
DEFAULT_BROKERS = "localhost:9092,localhost:9093,localhost:9094"
DATA_PATH = "./data/processed/air_quality_merged.parquet"

def json_serializer(data):
    # ƒê·∫£m b·∫£o datetime serialize ƒë√∫ng chu·∫©n ISO 8601
    if isinstance(data.get('datetime'), (datetime,)):
        data['datetime'] = data['datetime'].isoformat()
    return json.dumps(data).encode('utf-8')

def get_delay(mode):
    if mode == 'stress': return 0       # Max speed (Stress Test)
    elif mode == 'moderate': return 0.05 # ~20 msg/s
    else: return 1.0                    # 1 msg/s (Baseline)

def run_producer(mode, limit):
    brokers = os.getenv("KAFKA_BOOTSTRAP_SERVERS", DEFAULT_BROKERS).split(',')
    topic = os.getenv("KAFKA_TOPIC", DEFAULT_TOPIC)
    
    print(f"üöÄ [BENCHMARK PRODUCER] Mode: {mode.upper()} | Limit: {limit}")
    
    try:
        producer = KafkaProducer(
            bootstrap_servers=brokers,
            value_serializer=json_serializer,
            # T·ªëi ∆∞u h√≥a Batch g·ª≠i ƒëi cho ch·∫ø ƒë·ªô Stress
            linger_ms=10 if mode == 'stress' else 0,
            batch_size=16384
        )
    except Exception as e:
        sys.exit(f"‚ùå L·ªói Kafka: {e}")

    # S·ª≠ d·ª•ng Polars ƒë·ªÉ ƒë·ªçc file Parquet
    if not os.path.exists(DATA_PATH):
        sys.exit(f"‚ùå Kh√¥ng th·∫•y file data t·∫°i: {DATA_PATH}")
        
    try:
        df = pl.read_parquet(DATA_PATH)
        # Chuy·ªÉn ƒë·ªïi sang list dictionary ƒë·ªÉ l·∫∑p (iterator)
        records = df.to_dicts()
        print(f"‚úÖ ƒê√£ load {len(records)} b·∫£n ghi t·ª´ Parquet.")
    except Exception as e:
         sys.exit(f"‚ùå L·ªói ƒë·ªçc Parquet: {e}")

    delay = get_delay(mode)
    count = 0
    start_time = time.time()
    
    try:
        while True:
            for row in records:
                # Quan tr·ªçng: G√°n timestamp hi·ªán t·∫°i (UTC) ƒë·ªÉ ƒëo latency ch√≠nh x√°c
                row['datetime'] = datetime.now(timezone.utc).isoformat()
                
                producer.send(topic, row)
                count += 1
                
                if delay > 0:
                    time.sleep(delay)
                
                # Log throughput m·ªói 1000 tin
                if count % 1000 == 0:
                    elapsed = time.time() - start_time
                    print(f"   Sent {count} msgs. Rate: {count/elapsed:.2f} msg/s")
                
                if limit and count >= limit:
                    producer.flush()
                    total_time = time.time() - start_time
                    print(f"\n‚úÖ HO√ÄN TH√ÄNH.")
                    print(f"   - T·ªïng tin g·ª≠i: {count}")
                    print(f"   - Th·ªùi gian:    {total_time:.2f}s")
                    print(f"   - Throughput:   {count/total_time:.2f} msg/s")
                    return

    except KeyboardInterrupt:
        print("\n‚õî D·ª´ng b·ªüi ng∆∞·ªùi d√πng.")
        producer.close()

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("mode", choices=['baseline', 'moderate', 'stress'])
    parser.add_argument("--limit", type=int, default=5000)
    args = parser.parse_args()
    run_producer(args.mode, args.limit)